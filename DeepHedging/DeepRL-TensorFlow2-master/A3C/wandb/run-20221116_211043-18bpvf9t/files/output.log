1/1 [==============================] - 0s 304ms/step
1/1 [==============================] - 0s 311ms/step
1/1 [==============================] - 0s 276ms/step
1/1 [==============================] - 0s 281ms/step
1/1 [==============================] - 0s 316ms/step
1/1 [==============================] - 0s 293ms/step
1/1 [==============================] - 0s 285ms/step
1/1 [==============================] - 0s 285ms/step
1/1 [==============================] - 0s 319ms/step
1/1 [==============================] - 0s 311ms/step
1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - 0s 17ms/step
1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - 0s 16ms/step
1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - 0s 26ms/step
1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - 0s 17ms/step
1/1 [==============================] - 0s 14ms/step
1/1 [==============================] - 0s 17ms/step
1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - 0s 17ms/step
1/1 [==============================] - 0s 15ms/step
1/1 [==============================] - 0s 12ms/step
1/1 [==============================] - 0s 12ms/step
1/1 [==============================] - 0s 26ms/step
1/1 [==============================] - 0s 73ms/step
1/1 [==============================] - 0s 25ms/step
1/1 [==============================] - 0s 13ms/step
1/1 [==============================] - 0s 15ms/step
1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - 0s 27ms/step
1/1 [==============================] - 0s 17ms/step
1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - 0s 19ms/step
1/1 [==============================] - 0s 25ms/step
1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 29ms/step
1/1 [==============================] - 0s 34ms/step
1/1 [==============================] - 0s 36ms/step
1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - 0s 14ms/step
1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - 0s 198ms/step
1/1 [==============================] - 0s 187ms/step
1/1 [==============================] - 0s 179ms/step
1/1 [==============================] - 0s 165ms/step
1/1 [==============================] - 0s 167ms/step
1/1 [==============================] - 0s 138ms/step
1/1 [==============================] - 0s 29ms/step
1/1 [==============================] - 0s 146ms/step
1/1 [==============================] - 0s 112ms/step
1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - 0s 115ms/step
1/1 [==============================] - 0s 15ms/step
1/1 [==============================] - 0s 139ms/step
1/1 [==============================] - 0s 16ms/step
1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - 0s 16ms/step
1/1 [==============================] - 0s 17ms/step
1/1 [==============================] - 0s 16ms/step
1/1 [==============================] - 0s 17ms/step
1/1 [==============================] - 0s 14ms/step
WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x161e75000> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x161e76320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Exception in thread Exception in thread Exception in thread Exception in thread Thread-14Thread-15Exception in thread Thread-13Exception in thread Thread-10:
:
Traceback (most recent call last):
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
:
Traceback (most recent call last):
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
Thread-6Thread-8:
Traceback (most recent call last):
        Traceback (most recent call last):
:
Traceback (most recent call last):
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
:
Exception in thread self.run()  File "/Users/daehungo/yes/envs/colab/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
Traceback (most recent call last):
Thread-9self.run()  File "/Users/daehungo/yes/envs/colab/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    :
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 227, in run
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 227, in run
self.run()self.run()
Traceback (most recent call last):
    self.run()
self.run()  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 227, in run
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
self.train()
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 227, in run
self.train()      File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 227, in run
      File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 227, in run
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 203, in train
self.run()    self.train()        self.train()
self.train()
actor_loss = self.global_actor.train(
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 203, in train
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 227, in run
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 203, in train
self.train()
    actor_loss = self.global_actor.train(
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 65, in train
    self.opt.apply_gradients(zip(grads, self.model.trainable_variables))
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 738, in apply_gradients
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 203, in train
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 203, in train
      File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 203, in train
      File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 65, in train
    self.train()Exception in thread     Exception in thread     actor_loss = self.global_actor.train(        actor_loss = self.global_actor.train(
Thread-7return tf.__internal__.distribute.interim.maybe_merge_call(Thread-11:
actor_loss = self.global_actor.train(self.opt.apply_gradients(zip(grads, self.model.trainable_variables))
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 203, in train
:
Traceback (most recent call last):
actor_loss = self.global_actor.train(  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 65, in train
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 65, in train
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 65, in train
    Traceback (most recent call last):
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py", line 51, in maybe_merge_call
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    actor_loss = self.global_actor.train(      File "/Users/daehungo/yes/envs/colab/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
Exception in thread       File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 65, in train
self.opt.apply_gradients(zip(grads, self.model.trainable_variables))  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 738, in apply_gradients
self.opt.apply_gradients(zip(grads, self.model.trainable_variables))
    self.opt.apply_gradients(zip(grads, self.model.trainable_variables))Thread-12    return fn(strategy, *args, **kwargs)
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 65, in train
        self.run()
:
self.run()
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 738, in apply_gradients
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 738, in apply_gradients
return tf.__internal__.distribute.interim.maybe_merge_call(self.opt.apply_gradients(zip(grads, self.model.trainable_variables))
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 738, in apply_gradients
    Traceback (most recent call last):
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 797, in _distributed_apply
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 227, in run
        self.opt.apply_gradients(zip(grads, self.model.trainable_variables))      File "/Users/daehungo/yes/envs/colab/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 227, in run
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py", line 51, in maybe_merge_call
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 738, in apply_gradients
    return tf.__internal__.distribute.interim.maybe_merge_call(return tf.__internal__.distribute.interim.maybe_merge_call(
return tf.__internal__.distribute.interim.maybe_merge_call(                update_op = distribution.extended.update(
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 738, in apply_gradients
    self.train()self.train()self.run()
return fn(strategy, *args, **kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py", line 51, in maybe_merge_call
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py", line 51, in maybe_merge_call
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py", line 51, in maybe_merge_call
return tf.__internal__.distribute.interim.maybe_merge_call(
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2633, in update
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 203, in train
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 203, in train
return tf.__internal__.distribute.interim.maybe_merge_call(  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 227, in run
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 797, in _distributed_apply
return fn(strategy, *args, **kwargs)return fn(strategy, *args, **kwargs)return fn(strategy, *args, **kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py", line 51, in maybe_merge_call
        actor_loss = self.global_actor.train(  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py", line 51, in maybe_merge_call
actor_loss = self.global_actor.train(  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 797, in _distributed_apply
    self.train()  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 797, in _distributed_apply
    update_op = distribution.extended.update(
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2633, in update
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 797, in _distributed_apply
    return self._update(var, fn, args, kwargs, group)
    update_op = distribution.extended.update(return fn(strategy, *args, **kwargs)
    return fn(strategy, *args, **kwargs)
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 203, in train
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 65, in train
update_op = distribution.extended.update(
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 65, in train
return self._update(var, fn, args, kwargs, group)update_op = distribution.extended.update(  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3706, in _update
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2633, in update
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 797, in _distributed_apply
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 797, in _distributed_apply
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2633, in update
actor_loss = self.global_actor.train(    self.opt.apply_gradients(zip(grads, self.model.trainable_variables))        self.opt.apply_gradients(zip(grads, self.model.trainable_variables))  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3706, in _update
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2633, in update
        return self._update(var, fn, args, kwargs, group)
return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)update_op = distribution.extended.update(
  File "/Users/daehungo/Desktop/DataCapstone/github/DeepHedging/DeepRL-TensorFlow2-master/A3C/A3C_Continuous.py", line 65, in train
    update_op = distribution.extended.update(    return self._update(var, fn, args, kwargs, group)
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 738, in apply_gradients
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 738, in apply_gradients
return self._update(var, fn, args, kwargs, group)
return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3706, in _update
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3712, in _update_non_slot
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2633, in update
    self.opt.apply_gradients(zip(grads, self.model.trainable_variables))  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2633, in update
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3706, in _update
        return tf.__internal__.distribute.interim.maybe_merge_call(  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3706, in _update
    return tf.__internal__.distribute.interim.maybe_merge_call(
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3712, in _update_non_slot
return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)    result = fn(*args, **kwargs)
    return self._update(var, fn, args, kwargs, group)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 738, in apply_gradients
    return self._update(var, fn, args, kwargs, group)
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py", line 51, in maybe_merge_call
return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py", line 51, in maybe_merge_call
return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3712, in _update_non_slot
result = fn(*args, **kwargs)
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 595, in wrapper
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3706, in _update
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3706, in _update
return tf.__internal__.distribute.interim.maybe_merge_call(      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3712, in _update_non_slot
return fn(strategy, *args, **kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3712, in _update_non_slot
return fn(strategy, *args, **kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 595, in wrapper
result = fn(*args, **kwargs)
        return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)return func(*args, **kwargs)return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py", line 51, in maybe_merge_call
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 797, in _distributed_apply
result = fn(*args, **kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 797, in _distributed_apply
result = fn(*args, **kwargs)return func(*args, **kwargs)
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 595, in wrapper
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3712, in _update_non_slot
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 776, in apply_grad_to_update_var
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3712, in _update_non_slot
return fn(strategy, *args, **kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 595, in wrapper
    update_op = distribution.extended.update(update_op = distribution.extended.update(  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 595, in wrapper
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 776, in apply_grad_to_update_var
    return func(*args, **kwargs)
    result = fn(*args, **kwargs)    update_op = self._resource_apply_dense(grad, var, **apply_kwargs)      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 797, in _distributed_apply
result = fn(*args, **kwargs)
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2633, in update
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2633, in update
return func(*args, **kwargs)
return func(*args, **kwargs)update_op = self._resource_apply_dense(grad, var, **apply_kwargs)
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 776, in apply_grad_to_update_var
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 595, in wrapper
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py", line 177, in _resource_apply_dense
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 595, in wrapper
update_op = distribution.extended.update(  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 776, in apply_grad_to_update_var
    return self._update(var, fn, args, kwargs, group)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 776, in apply_grad_to_update_var
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py", line 177, in _resource_apply_dense
    return self._update(var, fn, args, kwargs, group)
        update_op = self._resource_apply_dense(grad, var, **apply_kwargs)
            return func(*args, **kwargs)
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2633, in update
return func(*args, **kwargs)update_op = self._resource_apply_dense(grad, var, **apply_kwargs)
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3706, in _update
return tf.raw_ops.ResourceApplyAdam(update_op = self._resource_apply_dense(grad, var, **apply_kwargs)return tf.raw_ops.ResourceApplyAdam(
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3706, in _update
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py", line 177, in _resource_apply_dense
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 776, in apply_grad_to_update_var
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 776, in apply_grad_to_update_var
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py", line 177, in _resource_apply_dense
return self._update(var, fn, args, kwargs, group)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py", line 412, in wrapper
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py", line 177, in _resource_apply_dense
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py", line 412, in wrapper
return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)
            return tf.raw_ops.ResourceApplyAdam(
update_op = self._resource_apply_dense(grad, var, **apply_kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3706, in _update
return tf.raw_ops.ResourceApplyAdam(update_op = self._resource_apply_dense(grad, var, **apply_kwargs)return f(**kwargs)
return tf.raw_ops.ResourceApplyAdam(return f(**kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3712, in _update_non_slot
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3712, in _update_non_slot
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py", line 412, in wrapper
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py", line 177, in _resource_apply_dense
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py", line 412, in wrapper
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py", line 177, in _resource_apply_dense
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py", line 1427, in resource_apply_adam
return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py", line 412, in wrapper
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py", line 1427, in resource_apply_adam
result = fn(*args, **kwargs)    result = fn(*args, **kwargs)
return f(**kwargs)
return tf.raw_ops.ResourceApplyAdam(
return tf.raw_ops.ResourceApplyAdam(return f(**kwargs)          File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3712, in _update_non_slot
return f(**kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 595, in wrapper
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 595, in wrapper
_ops.raise_from_not_ok_status(e, name)_ops.raise_from_not_ok_status(e, name)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py", line 1427, in resource_apply_adam
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py", line 412, in wrapper
          File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py", line 412, in wrapper
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py", line 1427, in resource_apply_adam
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py", line 1427, in resource_apply_adam
    result = fn(*args, **kwargs)    return func(*args, **kwargs)return func(*args, **kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
        _ops.raise_from_not_ok_status(e, name)
return f(**kwargs)
_ops.raise_from_not_ok_status(e, name)return f(**kwargs)
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 595, in wrapper
_ops.raise_from_not_ok_status(e, name)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 776, in apply_grad_to_update_var
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 776, in apply_grad_to_update_var
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py", line 1427, in resource_apply_adam
          File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
          File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py", line 1427, in resource_apply_adam
return func(*args, **kwargs)          File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
raise core._status_to_exception(e) from None  # pylint: disable=protected-accessraise core._status_to_exception(e) from None  # pylint: disable=protected-accessupdate_op = self._resource_apply_dense(grad, var, **apply_kwargs)update_op = self._resource_apply_dense(grad, var, **apply_kwargs)
_ops.raise_from_not_ok_status(e, name)raise core._status_to_exception(e) from None  # pylint: disable=protected-access
raise core._status_to_exception(e) from None  # pylint: disable=protected-access_ops.raise_from_not_ok_status(e, name)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 776, in apply_grad_to_update_var
raise core._status_to_exception(e) from None  # pylint: disable=protected-accesstensorflow.python.framework.errors_impltensorflow.python.framework.errors_impl  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py", line 177, in _resource_apply_dense
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py", line 177, in _resource_apply_dense
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
tensorflow.python.framework.errors_impl
..tensorflow.python.framework.errors_impl  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
            .update_op = self._resource_apply_dense(grad, var, **apply_kwargs)tensorflow.python.framework.errors_implInvalidArgumentErrorInvalidArgumentError.return tf.raw_ops.ResourceApplyAdam(    return tf.raw_ops.ResourceApplyAdam(raise core._status_to_exception(e) from None  # pylint: disable=protected-accessInvalidArgumentError
.: : InvalidArgumentError
raise core._status_to_exception(e) from None  # pylint: disable=protected-access
:   File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py", line 177, in _resource_apply_dense
InvalidArgumentErrorCannot assign a device for operation ResourceApplyAdam: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU
_Arg: GPU CPU
Colocation members, user-requested devices, and framework assigned devices, if any:
  var (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  ResourceApplyAdam (ResourceApplyAdam) /job:localhost/replica:0/task:0/device:GPU:0
Op: ResourceApplyAdam
Node attrs: use_locking=true, T=DT_DOUBLE, use_nesterov=false
Registered kernels:
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
	 [[{{node ResourceApplyAdam}}]] [Op:ResourceApplyAdam]Cannot assign a device for operation ResourceApplyAdam: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU
_Arg: GPU CPU
Colocation members, user-requested devices, and framework assigned devices, if any:
  var (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  ResourceApplyAdam (ResourceApplyAdam) /job:localhost/replica:0/task:0/device:GPU:0
Op: ResourceApplyAdam
Node attrs: use_locking=true, T=DT_DOUBLE, use_nesterov=false
Registered kernels:
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
	 [[{{node ResourceApplyAdam}}]] [Op:ResourceApplyAdam]:   File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py", line 412, in wrapper
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py", line 412, in wrapper
tensorflow.python.framework.errors_implCannot assign a device for operation ResourceApplyAdam: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU
_Arg: GPU CPU
Colocation members, user-requested devices, and framework assigned devices, if any:
  var (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  ResourceApplyAdam (ResourceApplyAdam) /job:localhost/replica:0/task:0/device:GPU:0
Op: ResourceApplyAdam
Node attrs: use_locking=true, T=DT_DOUBLE, use_nesterov=false
Registered kernels:
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
	 [[{{node ResourceApplyAdam}}]] [Op:ResourceApplyAdam]:
    Cannot assign a device for operation ResourceApplyAdam: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU
_Arg: GPU CPU
Colocation members, user-requested devices, and framework assigned devices, if any:
  var (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  ResourceApplyAdam (ResourceApplyAdam) /job:localhost/replica:0/task:0/device:GPU:0
Op: ResourceApplyAdam
Node attrs: use_locking=true, T=DT_DOUBLE, use_nesterov=false
Registered kernels:
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
	 [[{{node ResourceApplyAdam}}]] [Op:ResourceApplyAdam]tensorflow.python.framework.errors_impl        .
Cannot assign a device for operation ResourceApplyAdam: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU
_Arg: GPU CPU
Colocation members, user-requested devices, and framework assigned devices, if any:
  var (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  ResourceApplyAdam (ResourceApplyAdam) /job:localhost/replica:0/task:0/device:GPU:0
Op: ResourceApplyAdam
Node attrs: use_locking=true, T=DT_DOUBLE, use_nesterov=false
Registered kernels:
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
	 [[{{node ResourceApplyAdam}}]] [Op:ResourceApplyAdam]return tf.raw_ops.ResourceApplyAdam(
.return f(**kwargs)return f(**kwargs)InvalidArgumentError
InvalidArgumentError
:   File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py", line 412, in wrapper
:   File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py", line 1427, in resource_apply_adam
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py", line 1427, in resource_apply_adam
Cannot assign a device for operation ResourceApplyAdam: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU
_Arg: GPU CPU
Colocation members, user-requested devices, and framework assigned devices, if any:
  var (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  ResourceApplyAdam (ResourceApplyAdam) /job:localhost/replica:0/task:0/device:GPU:0
Op: ResourceApplyAdam
Node attrs: use_locking=true, T=DT_DOUBLE, use_nesterov=false
Registered kernels:
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
	 [[{{node ResourceApplyAdam}}]] [Op:ResourceApplyAdam]Cannot assign a device for operation ResourceApplyAdam: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU
_Arg: GPU CPU
Colocation members, user-requested devices, and framework assigned devices, if any:
  var (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  ResourceApplyAdam (ResourceApplyAdam) /job:localhost/replica:0/task:0/device:GPU:0
Op: ResourceApplyAdam
Node attrs: use_locking=true, T=DT_DOUBLE, use_nesterov=false
Registered kernels:
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
	 [[{{node ResourceApplyAdam}}]] [Op:ResourceApplyAdam]
return f(**kwargs)_ops.raise_from_not_ok_status(e, name)_ops.raise_from_not_ok_status(e, name)
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py", line 1427, in resource_apply_adam
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
            _ops.raise_from_not_ok_status(e, name)raise core._status_to_exception(e) from None  # pylint: disable=protected-accessraise core._status_to_exception(e) from None  # pylint: disable=protected-access
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
tensorflow.python.framework.errors_impltensorflow.python.framework.errors_impl..InvalidArgumentErrorInvalidArgumentError: : Cannot assign a device for operation ResourceApplyAdam: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU
_Arg: GPU CPU
Colocation members, user-requested devices, and framework assigned devices, if any:
  var (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  ResourceApplyAdam (ResourceApplyAdam) /job:localhost/replica:0/task:0/device:GPU:0
Op: ResourceApplyAdam
Node attrs: use_locking=true, T=DT_DOUBLE, use_nesterov=false
Registered kernels:
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
	 [[{{node ResourceApplyAdam}}]] [Op:ResourceApplyAdam]Cannot assign a device for operation ResourceApplyAdam: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU
_Arg: GPU CPU
Colocation members, user-requested devices, and framework assigned devices, if any:
  var (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  ResourceApplyAdam (ResourceApplyAdam) /job:localhost/replica:0/task:0/device:GPU:0
Op: ResourceApplyAdam
Node attrs: use_locking=true, T=DT_DOUBLE, use_nesterov=false
Registered kernels:
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
	 [[{{node ResourceApplyAdam}}]] [Op:ResourceApplyAdam]
raise core._status_to_exception(e) from None  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation ResourceApplyAdam: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU
_Arg: GPU CPU
Colocation members, user-requested devices, and framework assigned devices, if any:
  var (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  ResourceApplyAdam (ResourceApplyAdam) /job:localhost/replica:0/task:0/device:GPU:0
Op: ResourceApplyAdam
Node attrs: use_locking=true, T=DT_DOUBLE, use_nesterov=false
Registered kernels:
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
	 [[{{node ResourceApplyAdam}}]] [Op:ResourceApplyAdam]