WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1544d77f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x154688040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Exception in thread Exception in thread Thread-9:
Thread-8Exception in thread Traceback (most recent call last):
:
Thread-14  File "/Users/daehungo/yes/envs/colab/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
Exception in thread Traceback (most recent call last):
:
Thread-16  File "/Users/daehungo/yes/envs/colab/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
Traceback (most recent call last):
:
    Exception in thread   File "/Users/daehungo/yes/envs/colab/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
Traceback (most recent call last):
self.run()Thread-17      File "/Users/daehungo/yes/envs/colab/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    :
self.run()  File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 233, in run
    self.run()Traceback (most recent call last):
self.run()
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
      File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 233, in run
  File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 233, in run
self.train()Exception in thread   File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 233, in run
    Thread-13    self.train()self.run()  File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 209, in train
self.train():
Traceback (most recent call last):
self.train()
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
  File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 209, in train
actor_loss = self.global_actor.train(
  File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 67, in train
  File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 209, in train
    actor_loss = self.global_actor.train(    actor_loss = self.global_actor.train(
  File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 67, in train
    self.opt.apply_gradients(zip(grads, self.model.trainable_variables))
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 738, in apply_gradients
  File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 209, in train
Exception in thread
  File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 233, in run
    Exception in thread     Thread-10self.run()Exception in thread   File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 67, in train
    self.opt.apply_gradients(zip(grads, self.model.trainable_variables))Thread-11    actor_loss = self.global_actor.train(:
Thread-15return tf.__internal__.distribute.interim.maybe_merge_call(
:
self.train()
Traceback (most recent call last):
  File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 233, in run
:
self.opt.apply_gradients(zip(grads, self.model.trainable_variables))  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 738, in apply_gradients
Traceback (most recent call last):
  File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 67, in train
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
Traceback (most recent call last):
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py", line 51, in maybe_merge_call
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
      File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 209, in train
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
              File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 738, in apply_gradients
self.train()return tf.__internal__.distribute.interim.maybe_merge_call(        self.opt.apply_gradients(zip(grads, self.model.trainable_variables))    self.run()return fn(strategy, *args, **kwargs)
self.run()actor_loss = self.global_actor.train(
self.run()
  File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 209, in train
return tf.__internal__.distribute.interim.maybe_merge_call(  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py", line 51, in maybe_merge_call
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 738, in apply_gradients
  File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 233, in run
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 797, in _distributed_apply
      File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 233, in run
      File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 67, in train
  File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 233, in run
          File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py", line 51, in maybe_merge_call
    actor_loss = self.global_actor.train(return fn(strategy, *args, **kwargs)            return tf.__internal__.distribute.interim.maybe_merge_call(self.train()    update_op = distribution.extended.update(
self.train()self.train()self.opt.apply_gradients(zip(grads, self.model.trainable_variables))
return fn(strategy, *args, **kwargs)
  File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 67, in train
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 797, in _distributed_apply
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py", line 51, in maybe_merge_call
  File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 209, in train
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2633, in update
      File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 209, in train
      File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 209, in train
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 738, in apply_gradients
          File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 797, in _distributed_apply
self.opt.apply_gradients(zip(grads, self.model.trainable_variables))update_op = distribution.extended.update(            return fn(strategy, *args, **kwargs)actor_loss = self.global_actor.train(
actor_loss = self.global_actor.train(return tf.__internal__.distribute.interim.maybe_merge_call(actor_loss = self.global_actor.train(
return self._update(var, fn, args, kwargs, group)update_op = distribution.extended.update(  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 738, in apply_gradients
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2633, in update
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 797, in _distributed_apply
  File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 67, in train
      File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 67, in train
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py", line 51, in maybe_merge_call
      File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 67, in train
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3706, in _update
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2633, in update
    return self._update(var, fn, args, kwargs, group)        return tf.__internal__.distribute.interim.maybe_merge_call(self.opt.apply_gradients(zip(grads, self.model.trainable_variables))        update_op = distribution.extended.update(
self.opt.apply_gradients(zip(grads, self.model.trainable_variables))return fn(strategy, *args, **kwargs)
self.opt.apply_gradients(zip(grads, self.model.trainable_variables))
return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)
return self._update(var, fn, args, kwargs, group)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3706, in _update
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py", line 51, in maybe_merge_call
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 738, in apply_gradients
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2633, in update
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 738, in apply_gradients
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 797, in _distributed_apply
          File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 738, in apply_gradients
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3712, in _update_non_slot
          File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3706, in _update
    return fn(strategy, *args, **kwargs)return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)    return tf.__internal__.distribute.interim.maybe_merge_call(    return self._update(var, fn, args, kwargs, group)return tf.__internal__.distribute.interim.maybe_merge_call(
update_op = distribution.extended.update(
return tf.__internal__.distribute.interim.maybe_merge_call(
return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)result = fn(*args, **kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 797, in _distributed_apply
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3712, in _update_non_slot
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py", line 51, in maybe_merge_call
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3706, in _update
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py", line 51, in maybe_merge_call
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2633, in update
              File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py", line 51, in maybe_merge_call
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3712, in _update_non_slot
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 595, in wrapper
update_op = distribution.extended.update(result = fn(*args, **kwargs)return fn(strategy, *args, **kwargs)    return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)return fn(strategy, *args, **kwargs)
return self._update(var, fn, args, kwargs, group)
return fn(strategy, *args, **kwargs)result = fn(*args, **kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2633, in update
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 595, in wrapper
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 797, in _distributed_apply
return func(*args, **kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3712, in _update_non_slot
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 797, in _distributed_apply
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3706, in _update
    return func(*args, **kwargs)          File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 797, in _distributed_apply
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 595, in wrapper
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 776, in apply_grad_to_update_var
    return self._update(var, fn, args, kwargs, group)update_op = distribution.extended.update(update_op = distribution.extended.update(    return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)result = fn(*args, **kwargs)
update_op = distribution.extended.update(
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 776, in apply_grad_to_update_var
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3706, in _update
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2633, in update
update_op = self._resource_apply_dense(grad, var, **apply_kwargs)return func(*args, **kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2633, in update
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3712, in _update_non_slot
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 595, in wrapper
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2633, in update
    result = fn(*args, **kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py", line 177, in _resource_apply_dense
    return self._update(var, fn, args, kwargs, group)update_op = self._resource_apply_dense(grad, var, **apply_kwargs)return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 776, in apply_grad_to_update_var
Exception in thread Thread-12:
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 595, in wrapper
    return self._update(var, fn, args, kwargs, group)
Traceback (most recent call last):
    return func(*args, **kwargs)
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py", line 177, in _resource_apply_dense
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3712, in _update_non_slot
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
return tf.raw_ops.ResourceApplyAdam(
return self._update(var, fn, args, kwargs, group)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3706, in _update
return func(*args, **kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3706, in _update
update_op = self._resource_apply_dense(grad, var, **apply_kwargs)
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 776, in apply_grad_to_update_var
return tf.raw_ops.ResourceApplyAdam(
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py", line 412, in wrapper
self.run()      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3706, in _update
result = fn(*args, **kwargs)return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 776, in apply_grad_to_update_var
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py", line 177, in _resource_apply_dense
return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)
update_op = self._resource_apply_dense(grad, var, **apply_kwargs)
      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py", line 412, in wrapper
  File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 233, in run
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 595, in wrapper
return f(**kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3712, in _update_non_slot
return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)    update_op = self._resource_apply_dense(grad, var, **apply_kwargs)return tf.raw_ops.ResourceApplyAdam(  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3712, in _update_non_slot
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py", line 177, in _resource_apply_dense
return f(**kwargs)
    self.train()      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py", line 1427, in resource_apply_adam
return func(*args, **kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3712, in _update_non_slot
result = fn(*args, **kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py", line 177, in _resource_apply_dense
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py", line 412, in wrapper
result = fn(*args, **kwargs)
return tf.raw_ops.ResourceApplyAdam(
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py", line 1427, in resource_apply_adam
  File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 209, in train
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 776, in apply_grad_to_update_var
        result = fn(*args, **kwargs)      File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 595, in wrapper
return tf.raw_ops.ResourceApplyAdam(  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 595, in wrapper
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py", line 412, in wrapper
    return f(**kwargs)_ops.raise_from_not_ok_status(e, name)
_ops.raise_from_not_ok_status(e, name)
            actor_loss = self.global_actor.train(
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 595, in wrapper
update_op = self._resource_apply_dense(grad, var, **apply_kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py", line 412, in wrapper
return func(*args, **kwargs)return func(*args, **kwargs)return f(**kwargs)
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py", line 1427, in resource_apply_adam
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
  File "/Users/daehungo/Desktop/DataCapstone/github/jun/A3C_Continuous.py", line 67, in train
        return func(*args, **kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py", line 177, in _resource_apply_dense
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 776, in apply_grad_to_update_var
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 776, in apply_grad_to_update_var
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py", line 1427, in resource_apply_adam
return f(**kwargs)    _ops.raise_from_not_ok_status(e, name)
self.opt.apply_gradients(zip(grads, self.model.trainable_variables))
raise core._status_to_exception(e) from None  # pylint: disable=protected-access  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 776, in apply_grad_to_update_var
raise core._status_to_exception(e) from None  # pylint: disable=protected-accessreturn tf.raw_ops.ResourceApplyAdam(update_op = self._resource_apply_dense(grad, var, **apply_kwargs)update_op = self._resource_apply_dense(grad, var, **apply_kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py", line 1427, in resource_apply_adam
_ops.raise_from_not_ok_status(e, name)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 738, in apply_gradients
    tensorflow.python.framework.errors_impltensorflow.python.framework.errors_impl  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py", line 412, in wrapper
update_op = self._resource_apply_dense(grad, var, **apply_kwargs)  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py", line 177, in _resource_apply_dense
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py", line 177, in _resource_apply_dense
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
_ops.raise_from_not_ok_status(e, name)    ..    raise core._status_to_exception(e) from None  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.InvalidArgumentError
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py", line 177, in _resource_apply_dense
InvalidArgumentErrorInvalidArgumentError    :
        return tf.__internal__.distribute.interim.maybe_merge_call(:     : return f(**kwargs)Cannot assign a device for operation ResourceApplyAdam: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU
_Arg: GPU CPU
Colocation members, user-requested devices, and framework assigned devices, if any:
  var (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  ResourceApplyAdam (ResourceApplyAdam) /job:localhost/replica:0/task:0/device:GPU:0
Op: ResourceApplyAdam
Node attrs: use_locking=true, T=DT_DOUBLE, use_nesterov=false
Registered kernels:
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
	 [[{{node ResourceApplyAdam}}]] [Op:ResourceApplyAdam]return tf.raw_ops.ResourceApplyAdam(  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
raise core._status_to_exception(e) from None  # pylint: disable=protected-accessreturn tf.raw_ops.ResourceApplyAdam(
Cannot assign a device for operation ResourceApplyAdam: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU
_Arg: GPU CPU
Colocation members, user-requested devices, and framework assigned devices, if any:
  var (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  ResourceApplyAdam (ResourceApplyAdam) /job:localhost/replica:0/task:0/device:GPU:0
Op: ResourceApplyAdam
Node attrs: use_locking=true, T=DT_DOUBLE, use_nesterov=false
Registered kernels:
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
	 [[{{node ResourceApplyAdam}}]] [Op:ResourceApplyAdam]return tf.raw_ops.ResourceApplyAdam(
Cannot assign a device for operation ResourceApplyAdam: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU
_Arg: GPU CPU
Colocation members, user-requested devices, and framework assigned devices, if any:
  var (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  ResourceApplyAdam (ResourceApplyAdam) /job:localhost/replica:0/task:0/device:GPU:0
Op: ResourceApplyAdam
Node attrs: use_locking=true, T=DT_DOUBLE, use_nesterov=false
Registered kernels:
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
	 [[{{node ResourceApplyAdam}}]] [Op:ResourceApplyAdam]
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py", line 51, in maybe_merge_call
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py", line 1427, in resource_apply_adam
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py", line 412, in wrapper
tensorflow.python.framework.errors_impl  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py", line 412, in wrapper
raise core._status_to_exception(e) from None  # pylint: disable=protected-access  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py", line 412, in wrapper
    .
return fn(strategy, *args, **kwargs)InvalidArgumentError_ops.raise_from_not_ok_status(e, name)    return f(**kwargs)return f(**kwargs)tensorflow.python.framework.errors_impl
:
return f(**kwargs)
.  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 797, in _distributed_apply
Cannot assign a device for operation ResourceApplyAdam: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU
_Arg: GPU CPU
Colocation members, user-requested devices, and framework assigned devices, if any:
  var (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  ResourceApplyAdam (ResourceApplyAdam) /job:localhost/replica:0/task:0/device:GPU:0
Op: ResourceApplyAdam
Node attrs: use_locking=true, T=DT_DOUBLE, use_nesterov=false
Registered kernels:
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
	 [[{{node ResourceApplyAdam}}]] [Op:ResourceApplyAdam]  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py", line 1427, in resource_apply_adam
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py", line 1427, in resource_apply_adam
InvalidArgumentError
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py", line 1427, in resource_apply_adam
            :     update_op = distribution.extended.update(    _ops.raise_from_not_ok_status(e, name)_ops.raise_from_not_ok_status(e, name)Cannot assign a device for operation ResourceApplyAdam: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU
_Arg: GPU CPU
Colocation members, user-requested devices, and framework assigned devices, if any:
  var (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  ResourceApplyAdam (ResourceApplyAdam) /job:localhost/replica:0/task:0/device:GPU:0
Op: ResourceApplyAdam
Node attrs: use_locking=true, T=DT_DOUBLE, use_nesterov=false
Registered kernels:
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
	 [[{{node ResourceApplyAdam}}]] [Op:ResourceApplyAdam]raise core._status_to_exception(e) from None  # pylint: disable=protected-access
_ops.raise_from_not_ok_status(e, name)
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2633, in update
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
    tensorflow.python.framework.errors_impl    .raise core._status_to_exception(e) from None  # pylint: disable=protected-accessreturn self._update(var, fn, args, kwargs, group)
InvalidArgumentError
          File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3706, in _update
: tensorflow.python.framework.errors_implraise core._status_to_exception(e) from None  # pylint: disable=protected-accessraise core._status_to_exception(e) from None  # pylint: disable=protected-access.Cannot assign a device for operation ResourceApplyAdam: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU
_Arg: GPU CPU
Colocation members, user-requested devices, and framework assigned devices, if any:
  var (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  ResourceApplyAdam (ResourceApplyAdam) /job:localhost/replica:0/task:0/device:GPU:0
Op: ResourceApplyAdam
Node attrs: use_locking=true, T=DT_DOUBLE, use_nesterov=false
Registered kernels:
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
	 [[{{node ResourceApplyAdam}}]] [Op:ResourceApplyAdam]
tensorflow.python.framework.errors_impl
tensorflow.python.framework.errors_impl.InvalidArgumentErrorreturn self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group).InvalidArgumentError
InvalidArgumentError: :   File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3712, in _update_non_slot
Cannot assign a device for operation ResourceApplyAdam: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU
_Arg: GPU CPU
Colocation members, user-requested devices, and framework assigned devices, if any:
  var (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  ResourceApplyAdam (ResourceApplyAdam) /job:localhost/replica:0/task:0/device:GPU:0
Op: ResourceApplyAdam
Node attrs: use_locking=true, T=DT_DOUBLE, use_nesterov=false
Registered kernels:
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
	 [[{{node ResourceApplyAdam}}]] [Op:ResourceApplyAdam]
Cannot assign a device for operation ResourceApplyAdam: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU
_Arg: GPU CPU
Colocation members, user-requested devices, and framework assigned devices, if any:
  var (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  ResourceApplyAdam (ResourceApplyAdam) /job:localhost/replica:0/task:0/device:GPU:0
Op: ResourceApplyAdam
Node attrs: use_locking=true, T=DT_DOUBLE, use_nesterov=false
Registered kernels:
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
	 [[{{node ResourceApplyAdam}}]] [Op:ResourceApplyAdam]    :
result = fn(*args, **kwargs)Cannot assign a device for operation ResourceApplyAdam: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU
_Arg: GPU CPU
Colocation members, user-requested devices, and framework assigned devices, if any:
  var (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  ResourceApplyAdam (ResourceApplyAdam) /job:localhost/replica:0/task:0/device:GPU:0
Op: ResourceApplyAdam
Node attrs: use_locking=true, T=DT_DOUBLE, use_nesterov=false
Registered kernels:
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
	 [[{{node ResourceApplyAdam}}]] [Op:ResourceApplyAdam]
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 595, in wrapper
    return func(*args, **kwargs)
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py", line 776, in apply_grad_to_update_var
    update_op = self._resource_apply_dense(grad, var, **apply_kwargs)
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py", line 177, in _resource_apply_dense
    return tf.raw_ops.ResourceApplyAdam(
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/util/tf_export.py", line 412, in wrapper
    return f(**kwargs)
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/ops/gen_training_ops.py", line 1427, in resource_apply_adam
    _ops.raise_from_not_ok_status(e, name)
  File "/Users/daehungo/yes/envs/colab/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 7209, in raise_from_not_ok_status
    raise core._status_to_exception(e) from None  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation ResourceApplyAdam: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ResourceApplyAdam: CPU
_Arg: GPU CPU
Colocation members, user-requested devices, and framework assigned devices, if any:
  var (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  m (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  v (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  ResourceApplyAdam (ResourceApplyAdam) /job:localhost/replica:0/task:0/device:GPU:0
Op: ResourceApplyAdam
Node attrs: use_locking=true, T=DT_DOUBLE, use_nesterov=false
Registered kernels:
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
	 [[{{node ResourceApplyAdam}}]] [Op:ResourceApplyAdam]
1/1 [==============================] - 0s 165ms/step
1/1 [==============================] - 0s 165ms/step
1/1 [==============================] - 0s 186ms/step
1/1 [==============================] - 0s 189ms/step
1/1 [==============================] - 0s 235ms/step
1/1 [==============================] - 0s 225ms/step
1/1 [==============================] - 0s 152ms/step
1/1 [==============================] - 0s 198ms/step
1/1 [==============================] - 0s 231ms/step
1/1 [==============================] - 0s 230ms/step
0
None
1
None
222
None
22
222NoneNone
NoneNoneNoneNoneNone
1/1 [==============================] - 0s 16ms/step
1/1 [==============================] - 0s 11ms/step
1/1 [==============================] - 0s 15ms/step
10
None
10
None
12
None
1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - 0s 31ms/step
13
13None
None
1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - 0s 32ms/step
1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - ETA: 0s
1/1 [==============================] - 0s 22ms/step
1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - 0s 29ms/step
1/1 [==============================] - ETA: 0s
1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - ETA: 0sNone18None
1/1 [==============================] - 0s 18ms/step
1/1 [==============================] - 0s 18ms/step0
1/1 [==============================] - 0s 19ms/step
None22
22None
None
1/1 [==============================] - 0s 20ms/step
25
None
1/1 [==============================] - 0s 17ms/step
26
None
1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - 0s 20ms/step
27
None
1/1 [==============================] - ETA: 0s
1/1 [==============================] - 0s 24ms/step
None28
1/1 [==============================] - ETA: 0s
1/1 [==============================] - 0s 26ms/step
1/1 [==============================] - 0s 27ms/step
29
1/1 [==============================] - ETA: 0s
1/1 [==============================] - 0s 32ms/step
None
2
None
1/1 [==============================] - 0s 21ms/step
1/1 [==============================] - 0s 35ms/step
3
None3
1/1 [==============================] - ETA: 0s
1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - 0s 29ms/step
1/1 [==============================] - 0s 22ms/step
5
None
6
None6
None
1/1 [==============================] - 0s 22ms/step
8
None
1/1 [==============================] - 0s 16ms/step
1/1 [==============================] - 0s 27ms/step
1/1 [==============================] - 0s 17ms/step
9
None
10
9None
None
1/1 [==============================] - 0s 28ms/step
12
None
1/1 [==============================] - 0s 24ms/step
1/1 [==============================] - 0s 16ms/step
1/1 [==============================] - ETA: 0s
1/1 [==============================] - 0s 19ms/step
13
None
1/1 [==============================] - ETA: 0s
1/1 [==============================] - 0s 26ms/step
None15
1/1 [==============================] - ETA: 0s
1/1 [==============================] - 0s 13ms/step
None
17
None
1/1 [==============================] - 0s 24ms/step
18
None
1/1 [==============================] - 0s 144ms/step
1/1 [==============================] - 0s 149ms/step
1/1 [==============================] - 0s 173ms/step
1/1 [==============================] - 0s 141ms/step
1/1 [==============================] - 0s 26ms/step
19
None
1/1 [==============================] - 0s 160ms/step
1/1 [==============================] - 0s 17ms/step
1/1 [==============================] - 0s 181ms/step
1/1 [==============================] - 0s 26ms/step
1/1 [==============================] - 0s 138ms/step
1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - 0s 153ms/step
1/1 [==============================] - 0s 111ms/step
1/1 [==============================] - 0s 23ms/step
1/1 [==============================] - 0s 20ms/step
1/1 [==============================] - 0s 98ms/step
1/1 [==============================] - 0s 17ms/step
1/1 [==============================] - 0s 14ms/step
1/1 [==============================] - 0s 17ms/step
1/1 [==============================] - 0s 17ms/step
1/1 [==============================] - 0s 12ms/step